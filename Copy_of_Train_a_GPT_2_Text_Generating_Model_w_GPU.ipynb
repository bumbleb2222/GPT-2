{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bumbleb2222/GPT-2/blob/master/Copy_of_Train_a_GPT_2_Text_Generating_Model_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: November 10th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "57b0cc80-1e86-4eac-efbd-d645ada82a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "outputId": "65d93415-1d4a-4d61-b4ae-3a16206854cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 23 18:27:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "outputId": "b2ba68bd-34a3-46ca-f2cc-17683d8d48af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 479Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 114Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 952Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:08, 162Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 796Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 136Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 261Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "outputId": "8736c3a8-a298-484c-d5a8-c530f9818bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXe9LAblTOfM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BWkoMrqTPAQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"Training Romance.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "34e7e7b1-7669-4156-aff2-eb0213e52ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 642290 tokens\n",
            "Training...\n",
            "[10 | 23.67] loss=3.02 avg=3.02\n",
            "[20 | 38.99] loss=2.70 avg=2.86\n",
            "[30 | 54.54] loss=2.87 avg=2.86\n",
            "[40 | 70.34] loss=2.55 avg=2.78\n",
            "[50 | 86.45] loss=2.40 avg=2.70\n",
            "[60 | 102.82] loss=2.55 avg=2.68\n",
            "[70 | 119.48] loss=2.58 avg=2.66\n",
            "[80 | 136.49] loss=2.88 avg=2.69\n",
            "[90 | 153.43] loss=2.47 avg=2.67\n",
            "[100 | 170.11] loss=2.25 avg=2.62\n",
            "[110 | 186.71] loss=2.08 avg=2.57\n",
            "[120 | 203.40] loss=2.69 avg=2.58\n",
            "[130 | 220.20] loss=2.20 avg=2.55\n",
            "[140 | 237.03] loss=2.49 avg=2.55\n",
            "[150 | 253.83] loss=2.81 avg=2.56\n",
            "[160 | 270.62] loss=2.46 avg=2.56\n",
            "[170 | 287.38] loss=2.65 avg=2.56\n",
            "[180 | 304.14] loss=2.23 avg=2.54\n",
            "[190 | 320.90] loss=2.99 avg=2.57\n",
            "[200 | 337.64] loss=2.07 avg=2.54\n",
            "======== SAMPLE 1 ========\n",
            ".\n",
            "\n",
            "\n",
            "The only consolation to the one thing that kept him from being a monster.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Chapter 22\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\"You didn't say anything when I told the other man I was your family. I think that might have been the last thing she wanted. I would have liked it if you had said the truth. How could I ever tell?\"\n",
            "\n",
            "\n",
            "He nodded slowly, almost as if he was trying to remember what had just happened. \"What's she like?\"\n",
            "\n",
            "\n",
            "\"She's not all that different from you. I'm so glad that we didn't go down there.\"\n",
            "She had told him about her parents, the doctor told her. There was the time when she'd met him in Seattle and he'd had a conversation with her, just like they did each day. \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " He was in a bar, trying not to think about his mother and his grandparents. He was already planning his next date with her. They lived in Seattle, and the doctor wanted to talk to him to make sure he was okay. \n",
            "But he'd done more than that when he'd met her. He'd been a boy, and he'd been afraid of talking to anyone for a long time. It had left him at a crossroads, and it would never be the same again. Not when she talked to him about the doctor. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "He was in a bar, trying not to think about his mother and his grandparents. The doctor had asked him to come with her, and he'd made good faith out of telling her the whole truth. \n",
            "For the doctor to make a fool out of him, he shouldn't have allowed his mind to wander. Not when it came to talking to the only person that mattered to him more than anything. He didn't want to make her seem like one of those people who wanted anything more than a loving explanation. \"How did you find out I was your father?\"\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "She stared at him. \"I found out about you the way that you found out me.\"\n",
            "\"But you knew when you were little?\"\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\"It had nothing to do with my parents.\" She laughed. \"I knew him while I was a kid. He wasn't a great guy. He had no idea I was your mother. He didn't talk to me about it or anything. But his face told me it was true.\" She didn't have to imagine he could have died. \n",
            "He glanced at her over his shoulder until she started smiling. His eyes followed her with a smile she couldn't find anywhere else. She watched his face, which had been transformed from a smile to a smile that was hard wired to give pleasure. \n",
            "\"What kind of smile is that?\" asked the doctor. \"That's because you have a very good sense of humor. It means you've got a very good sense of humor.\" \n",
            "\"I can't be as funny as that.\" Tears stung her eyes. \"I'm not funny. I've got to make this straight.\" \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "When she'd gotten home she'd started looking for what had been knocked out of her memory by the doctor. It wasn't the time to just be grateful that she'd been able to come over again. She'd wanted to make sure all the people that knew her didn't know who she was, because she knew them. \n",
            "It was the doctor who had shown her who he was. She went to his house, took a seat at the dining table, and listened for any unusual noises. \n",
            "\"I didn't find a sound on my way here. I hope you didn't hear a knock or a door opening, or something.\"\n",
            "\"Something? Did something happen?\"\n",
            "\"Nothing, honey. You looked better and soundly.\" He looked as though he wasn't going to be happy, and so had she. The tears poured down her cheeks. \"I'm so glad that you weren't hit by a car or the explosion.\" \n",
            "She looked at the clock on the side of the bed. \"I didn't find a time that made me feel better than the one I'm sitting here now.\"\n",
            "\"You're so sorry.\" The doctor held her down, and he pressed his lips to hers. \"This wasn't the least bit wise, and in this moment I don't know what I would have done differently. Would I have stayed home, or went out and find some kind of answers in a way that you didn't expect? For that matter, who would I have been if what you're going through were to happen again?\"\n",
            "Her hands were gripping the edges of the bed. The doctor had pulled his hands away, and she took the small pillow out of his hands and placed it on the edge of the bed. He stood up, but that didn't surprise her. He was just happy\n",
            "\n",
            "[210 | 379.14] loss=1.98 avg=2.51\n",
            "[220 | 395.96] loss=2.61 avg=2.52\n",
            "[230 | 412.78] loss=1.19 avg=2.45\n",
            "[240 | 429.66] loss=2.03 avg=2.43\n",
            "[250 | 446.51] loss=2.63 avg=2.44\n",
            "[260 | 463.42] loss=2.44 avg=2.44\n",
            "[270 | 480.34] loss=2.64 avg=2.45\n",
            "[280 | 497.29] loss=3.03 avg=2.47\n",
            "[290 | 514.26] loss=2.63 avg=2.48\n",
            "[300 | 531.19] loss=2.28 avg=2.47\n",
            "[310 | 548.10] loss=2.01 avg=2.46\n",
            "[320 | 565.03] loss=2.77 avg=2.47\n",
            "[330 | 581.93] loss=2.41 avg=2.46\n",
            "[340 | 598.86] loss=2.59 avg=2.47\n",
            "[350 | 615.80] loss=2.81 avg=2.48\n",
            "[360 | 632.72] loss=1.49 avg=2.45\n",
            "[370 | 649.62] loss=1.77 avg=2.43\n",
            "[380 | 666.49] loss=1.82 avg=2.41\n",
            "[390 | 683.40] loss=2.72 avg=2.42\n",
            "[400 | 700.27] loss=2.32 avg=2.41\n",
            "======== SAMPLE 1 ========\n",
            ", a little girl. Don’t you think it’s about time I told you about yourself?\"\n",
            "“Mom, it’s true as you say. But I have a feeling you’re more interested in knowing what I am now than what I’d like to become. And what is it doing here?”\n",
            "Her expression hardened. It wasn’t just her eyes burning with heat that she had seen during her mother’s previous conversation with Colin, it was her expression that was making her angry.\n",
            "“Oh, Mom. Are you mad? Are you angry at me?”\n",
            "“I think I might have just had more to do this morning than my mom’s cooking lesson taught me. I’ve got some things to say to Dad about. Is there something I can say to you, Mom?”\n",
            "Colin’s small voice cut through all of the chaos and the sound of the kitchen door open crashing.\n",
            "“Ain’t I the one that said I’d make dinner for you?”\n",
            "“There’s no getting around it, honey. You’ve told me what to do. I did what you said right away. And that’s what has gotten me into trouble. What’s causing the commotion? Was what you said going to be repeated more than once? The man has been rude. For once she’d like you to apologize.”\n",
            "Gracie’s face crumpled into a sad smoky look.\n",
            "Colin reached across and hugged her shoulder. It was too much for the grief-stricken woman.\n",
            "“We need to talk about Mom,” Colin said.\n",
            "“What do you mean?” Her gaze shot around the table. She was looking for someone with whom she could talk.\n",
            "Colin’s tone was firm.\n",
            "“About everything,” she snapped.\n",
            "Colin’s hands stilled where Colin’s gently cupped her shoulder.\n",
            "“And about where you’d hoped to go,” Colin went on, his tone firm and his gaze locked on her.\n",
            "“I want to go.”\n",
            "Colin’s hand stilled where Colin’s, as well.\n",
            "“That’s going to be hard enough.”\n",
            "Colin turned and left.\n",
            "“Good. So, you’re just going to hang on tight because you know it will be hard doing you have to deal with all of this right now?”\n",
            " “Well, maybe I can’t. But that doesn’t mean I won’t try to do it. And I won’t let you down.”\n",
            "Colin didn’t speak up or ask again as the silence descended over the table. It was too much for her. “Good. So, anyway, you have something to think about. About why I chose you to go to the party, or the wedding. Why I decided to. Whatever it was I wanted to tell you before we could.”\n",
            "She closed her eyes and wondered about the rest of the conversation she’d missed.\n",
            "“That’s about the most selfish thing you have to say about a brother. If I’d go with anyone and they were any one of you, you would want to see them. You might even want to put a little pressure on their family members, the ones who want so much.”\n",
            "Gracie’s eyes were closed, her mouth opened in a silent gesture. She seemed to do some kind of dance reaction there.\n",
            "“The people you want to talk to, the people you want to be. Then everything else is just your imagination,” Colin said, returning to his words.\n",
            "“Of course, I knew it!” She cleared her throat. Colin’s eyes hardened. “Well, it’s not a bad way to start.”\n",
            "Colin’s gaze moved across the table and back up to her. That was when she saw a glazed look in his eye. That was when she noticed that he was moving the moment they were seated so that his hand moved over hers, along her body.\n",
            "It was strange, seeing him move, that he didn’t seem to notice the subtle movements she was making with one arm around hers and the other hand resting lightly on the table. The table had moved so slightly in that instant that he hadn’t noticed.\n",
            "“I think I can understand that,” she said softly.\n",
            "“You can say the same thing about a lot in this world. And it’s true. The moment I went out\n",
            "\n",
            "[410 | 739.66] loss=2.73 avg=2.42\n",
            "[420 | 756.48] loss=2.59 avg=2.43\n",
            "[430 | 773.37] loss=2.14 avg=2.42\n",
            "[440 | 790.28] loss=2.09 avg=2.41\n",
            "[450 | 807.20] loss=2.35 avg=2.41\n",
            "[460 | 824.08] loss=2.16 avg=2.40\n",
            "[470 | 840.97] loss=2.03 avg=2.39\n",
            "[480 | 857.84] loss=1.41 avg=2.37\n",
            "[490 | 874.70] loss=1.77 avg=2.35\n",
            "[500 | 891.51] loss=1.81 avg=2.34\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 916.10] loss=1.79 avg=2.32\n",
            "[520 | 933.31] loss=2.72 avg=2.33\n",
            "[530 | 950.38] loss=2.01 avg=2.33\n",
            "[540 | 967.24] loss=2.63 avg=2.33\n",
            "[550 | 984.05] loss=2.36 avg=2.33\n",
            "[560 | 1000.90] loss=2.13 avg=2.33\n",
            "[570 | 1017.86] loss=1.40 avg=2.31\n",
            "[580 | 1034.79] loss=1.66 avg=2.29\n",
            "[590 | 1051.67] loss=2.77 avg=2.30\n",
            "[600 | 1068.50] loss=1.88 avg=2.29\n",
            "======== SAMPLE 1 ========\n",
            " I can help you.\"\n",
            "\"I need to leave.\"\n",
            "He was tired of being a recluse, the kind of guy who would stay home and be an odd duck in a world that didn't need one. \"You can't stay there. You're in Nova Scotia.\" He stood up from the chair, crossed his arms, and took a deep breath. In the distance, he could hear the sound of birds chirping. \"I know.\"\n",
            "\"You've been doing something right this summer. You've taken my father and father-in-law out to the woods, and we've been talking about what we want to do about the ranch. Are we building a giant home for my family?\"\n",
            "He didn't think it was a home at all, but the thought was starting to make him smile. \"I'm not being selfish. I've got a lot of grandkids coming up. I want to take some of those kids into the world. I know my parents want to live and work in the outdoors, but it doesn't make me want to work hard for them. You can't look at me as if I have no desire to do what my father and mother want to do.\"\n",
            "\"The biggest challenge of my life at the moment?\"\n",
            "            \"I'll tell you the biggest challenge of my life. I'm sick and tired of being outclassed on a daily basis. The last few years have probably been the most difficult of my life.\"\n",
            "He looked down at his bare feet, then crossed his arms and glared back at Natalie. \"Natalie.\"\n",
            "She smiled. \"I heard. I was always looking for someone to take a look at.\"\n",
            "He pulled her into his arms. \"You wouldn't have been in our life if it weren't for you and that's the most important thing.\"\n",
            "They settled comfortably into each other's arms. Natalie took a long, slow breath, then said, \"I'll see you in a month, then come back to the Big Easy and talk to me about what I can do for you.\"\n",
            "He smiled. \"Thank you.\"\n",
            "\n",
            "***\n",
            "Natalie stood at the top of the stairs, her bag slung over her shoulder. \"Good. I'm going to go see the sales lady. I've got a friend here named Tom for you. I'm going through hell to get my stuff back.\"\n",
            " \"You've done a good job, Bella.\"\n",
            "Bella frowned. \"My mum used to tell me to have fun.\" Beads of sweat clumped in the corner of her eye. \"I've been working long hours, but I love a good job. It's what I love.\"\n",
            "Natalie had some nice things going, but the last two days had been more than she could have managed in a week. \"I don't want to be a burden to anyone. But how do you feel about being back to Big Apple, anyway?\"\n",
            "When Bella had first started her job, her apartment had taken up the majority of her work hours. \"Do I have to clean my apartment?\"\n",
            "\"Bella, you can stay here. Tom's going out on a shopping trip. He might not have much left for you after that, but you can stay there.\"\n",
            "Tom grinned. \"It's a great apartment. I've got the best clothes, and I work from a great, wonderful, home away from home.\"\n",
            "Bella felt her heart sink. \"When have you ever been in this area?\"\n",
            "Tom nodded. \"A fortnight before I started working in Nova Scotia. Then two weeks after that, when it snowed.\"\n",
            "Bella sighed. \"I wouldn't stay away from people, but then I wouldn't either.\"\n",
            "Tom chuckled. \"If someone can't handle something with you, they can't handle it in five minutes. Not when there are other things to do before you get your clothes out the day after you leave the apartment.\"\n",
            "Bella glanced across the room. \"They can go to the mall with me.\" She nodded to Tom. \"Tom's working out where he wants to build a fence around the building. It's his property, so he should have the right to do that. But nobody's property can come back to where we were before.\"\n",
            "\"Right. You've been planning what's not going to happen. You haven't worked out where you want to go with that.\"\n",
            "Bella frowned as she tried to imagine all the things she wanted to make happen. She couldn't imagine a time when her parents weren't home, or when she didn't need to get a car fixed. And if she was going to do this, she had to be in a good place at the time. \"If you're not prepared, the future doesn't matter.\"\n",
            "\"I'm not prepared.\" Bella held the back of her hand in front of her face. \"I have my priorities, and I have to go with a plan.\" She looked for a way\n",
            "\n",
            "[610 | 1108.24] loss=2.11 avg=2.29\n",
            "[620 | 1125.04] loss=2.21 avg=2.29\n",
            "[630 | 1141.89] loss=1.08 avg=2.26\n",
            "[640 | 1158.77] loss=1.53 avg=2.25\n",
            "[650 | 1175.67] loss=1.54 avg=2.23\n",
            "[660 | 1192.62] loss=2.14 avg=2.23\n",
            "[670 | 1209.54] loss=2.24 avg=2.23\n",
            "[680 | 1226.45] loss=2.62 avg=2.24\n",
            "[690 | 1243.37] loss=1.41 avg=2.22\n",
            "[700 | 1260.23] loss=1.83 avg=2.21\n",
            "[710 | 1277.07] loss=2.25 avg=2.22\n",
            "[720 | 1293.92] loss=2.41 avg=2.22\n",
            "[730 | 1310.78] loss=2.12 avg=2.22\n",
            "[740 | 1327.62] loss=1.84 avg=2.21\n",
            "[750 | 1344.45] loss=2.22 avg=2.21\n",
            "[760 | 1361.28] loss=2.44 avg=2.21\n",
            "[770 | 1378.10] loss=2.45 avg=2.22\n",
            "[780 | 1394.93] loss=2.40 avg=2.22\n",
            "[790 | 1411.78] loss=1.82 avg=2.22\n",
            "[800 | 1428.59] loss=1.66 avg=2.20\n",
            "======== SAMPLE 1 ========\n",
            " of the girl he'd been dating for a while. “I’m surprised that you were even able to keep a lid on your feelings. I thought I could find a way to beat you up, but you wouldn’t let me. Even in my room, I wasn’t allowed to.” “There were no restraints, no rings around my finger, and I got to pick what I did.” \n",
            "\n",
            "“I know,” Luke said in a dry and dispassionate tone. “What do you mean, just let me do? The chains were there to keep me where I couldn’t hurt you. I can’t touch you, c'mon. I mean, that’s what parents are for, right? You don’t have to worry about anything like that.”\n",
            "\n",
            "“I had to.” Natalie nodded slowly, her head down in a helpless look on her face. “It was the only thing left. The reason that I wasn’t able to find you is because I was hiding from the thought that you wanted to kill me. I couldn’t hurt you.”\n",
            "\n",
            "“Why did you kill me?” \n",
            "\n",
            "“I wanted to destroy you, Luke. I wanted to kill both of you.” \n",
            "\n",
            "“But you’re not killing me,” Natalie said in amazement. “You’re not going to kill me. I just need time to myself.”\n",
            "\n",
            "“I wish you were. There would be no doubt you wanted me dead,” Luke said with relief.\n",
            "\n",
            "“You were the one who convinced me not to do it. And I’m sorry about that.” \n",
            "\n",
            "The smile on her face was the first indication that she thought their conversation would go the other way. “What about the other thing you said to me? I would have loved to have found you, to have found someone who could be my father.”\n",
            "\n",
            "His eyebrows rose in puzzlement. “What would that be like, Luke? Finding your father with somebody else? Getting to know him in a way that neither of you could imagine?”\n",
            "\n",
            "“You’re not my father, and neither of us is going to find him. Not now, not ever.” \n",
            "\n",
            "“That’s what I’m getting at. You wouldn’t find your father with somebody else, Luke. You wouldn’t find your father with a different person.” \n",
            "\n",
            "“I can’t lie. He’d hurt somebody close to you. He would have felt bad for the years he wouldn’t get to spend with you,” Natalie said thoughtfully. “But he would have wanted you to find him. To find someone who loved him, someone who cared about him. Someone who didn’t want to see what he did to you disappear.”\n",
            "\n",
            "“I don’t want to feel that someone.” \n",
            "\n",
            "The smile on Natalie’s face disappeared. “What has that got to do with finding out who your father is?” “Nothing. I’m going to get some more chocolate while the café's still open.”\n",
            "\n",
            "“I’m afraid I’m not seeing the right things,” he muttered. He sat down in the small of the café with his arms crossed over his chest, his back against the wooden tables. “That was stupid of me.” \n",
            "\n",
            "“I hope you don’t mean that you don’t want to find out,” Natalie said firmly. “The only reason I even considered dating someone was because I loved him. You were the one who’d stopped talking. And you weren’t even the one who’d started the break-up.” \n",
            "\n",
            "“I loved him,” Luke snapped. “I’ve got to love what you did to me,” he shouted, still not looking at his watch. “I would have loved to live again.”\n",
            "\n",
            "“I’m sorry.” Natalie cleared her throat. “There was nothing. I just don’t believe I’d want to be that person again. He was the most incredible man ever to exist. No matter what happened, no matter how much I changed, he always stood by me, always was the one to help me.” \n",
            "\n",
            "“What have you changed to, Natalie? What have you gained? Why haven’t you told me about it?” \n",
            "\n",
            "“The\n",
            "\n",
            "[810 | 1468.07] loss=2.65 avg=2.21\n",
            "[820 | 1484.89] loss=1.13 avg=2.19\n",
            "[830 | 1501.77] loss=1.36 avg=2.18\n",
            "[840 | 1518.70] loss=2.00 avg=2.18\n",
            "[850 | 1535.61] loss=2.64 avg=2.18\n",
            "[860 | 1552.51] loss=2.44 avg=2.19\n",
            "[870 | 1569.37] loss=0.98 avg=2.17\n",
            "[880 | 1586.21] loss=1.54 avg=2.16\n",
            "[890 | 1603.05] loss=1.84 avg=2.15\n",
            "[900 | 1619.88] loss=2.63 avg=2.16\n",
            "[910 | 1636.73] loss=2.05 avg=2.16\n",
            "[920 | 1653.59] loss=1.83 avg=2.15\n",
            "[930 | 1670.45] loss=2.46 avg=2.16\n",
            "[940 | 1687.32] loss=0.99 avg=2.14\n",
            "[950 | 1704.23] loss=1.90 avg=2.13\n",
            "[960 | 1721.12] loss=2.07 avg=2.13\n",
            "[970 | 1738.00] loss=1.22 avg=2.12\n",
            "[980 | 1754.89] loss=0.95 avg=2.10\n",
            "[990 | 1771.77] loss=1.05 avg=2.08\n",
            "[1000 | 1788.67] loss=1.50 avg=2.07\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "outputId": "af6ac06d-b088-4ce9-d43a-4067b34e540e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "“There you are, you’re not going to believe this,” Cole whined, so softly that I almost had a heart attack.\n",
            "\n",
            "I almost did, but I held my breath. “I knew you’d make it,” I said, smiling. I’d seen the way Cole’s eyes lit up when he first saw me. “I’m telling you, Cole, I’m not going to believe this.”\n",
            "\n",
            "“I’m not scared of heights,” he said, his voice a little hoarse. “I’m scared of heights.”\n",
            "\n",
            "“I’m not scared of heights,” I repeated.\n",
            "\n",
            "He stopped breathing and his shoulders trembled. “I’m not scared,” he whispered, his hands clenching into fists to stop them from shaking. “I’m scared of you, Cole.”\n",
            "\n",
            "I pulled back. “I’m Cole,” I said softly.\n",
            "\n",
            "He nodded. “You’re safe with me.”\n",
            "\n",
            "I held my breath and waited for him to say it again, but he didn’t.\n",
            "\n",
            "“I’m…” He clenched his teeth and stuttered, his eyes distant and hard. “I’m scared.”\n",
            "\n",
            "“I’m with you,” I whispered. “I’m OK, Cole.”\n",
            "\n",
            "He nodded again, his voice full of hate.\n",
            "\n",
            "I felt my blood pressure rise.\n",
            "\n",
            "He wasn’t going to let me fall for him.\n",
            "\n",
            "“I want you to know,” he said softly, “I love you.”\n",
            "\n",
            "He kissed my forehead and nodded his head to the music.\n",
            "\n",
            "“I love you, too.”\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "11\n",
            "\n",
            "\n",
            "Oakley\n",
            "\n",
            "\n",
            "\n",
            "“Do you want to go inside?” Cole asked as we stepped outside, and I nodded and opened the door. It was cold out here and we needed to warm up. We’d been in the loft for hours. Cole’s bed was immovable and I knew it was too late to go back inside. “You don’t have to stay in bed,” he said.\n",
            "\n",
            "I nodded and walked inside. Cole was lying on his side. His hair was in a ponytail and he was wearing a sweater underneath it. Cole’s arms were wrapped around me and I wanted to pull him closer.\n",
            "\n",
            "There was no sign of him in the room, but I knew that was because he was in bed. I’d never felt so loved in my life.\n",
            "\n",
            "“You look uncomfortable.” He whispered softly, kissing my forehead. “Would you like some company?”\n",
            "\n",
            "My eyes barely left his as I opened the door. Cole’s body was pressed against mine, his body touching mine in a strange way. It was so quiet and so peaceful. I wanted to stay and remember.\n",
            "\n",
            "He pulled me into him and wrapped his arms around me.\n",
            "\n",
            "I wanted to stay and remember.\n",
            "\n",
            "“Are you ready?” He asked, kissing my forehead and forcing my lips to leave his neck before he could. I nodded and smiled, and he kissed me.\n",
            "\n",
            "“Good.” I jumped off the bed and ran to where Cole was sitting. I jumped up and grabbed his arm so he could sit down. “Ready?”\n",
            "\n",
            "He nodded and jumped onto the bed.\n",
            "\n",
            "I sat down beside him and ran my hands up his back and then up his arms. It was the most amazing feeling ever. I was so close to him that I could feel the hairs on my arms standing on end.\n",
            "\n",
            "“Who’s ready?” He asked softly, and I nodded. “I’ll be with you the whole time.”\n",
            "\n",
            "He nodded and kissed me.\n",
            "\n",
            "The only sound I heard was the click of the bedframe sliding open. Cole’s body shuddered as we moved to the living room. He pulled a few items out of the bag he’d placed on the bedside table. “I’ll take you into the kitchen,” he said, looking around the corner of the room.\n",
            "\n",
            "“Thank you,” I whispered, hugging him close.\n",
            "\n",
            "Cole turned his head. He didn’t have a lot of time to spare because he had to leave.\n",
            "\n",
            "“We’ll go into town,” he said, smiling at the people standing in front of him\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "outputId": "526dbd1b-f076-4f47-a42b-058ab4a35b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LORD WILLOUGHBY:\n",
            "That, by the way, Clarence and I have done good side by side;\n",
            "And yet side we, and he side we have done ill.\n",
            "\n",
            "KING RICHARD II:\n",
            "Why then 'tis done ill. O, how should I ease it?\n",
            "Side with him and my brother, my sovereign!\n",
            "Side wither away, and as night falls,\n",
            "Like to the farthest morning to my last,\n",
            "Side wither away, and as morning comes,\n",
            "Like to the furthest afternoon to my last!\n",
            "Side wither away, and as our fortunes turn,\n",
            "Like to the furthest afternoon to our last!\n",
            "\n",
            "QUEEN MARGARET:\n",
            "What is this? counsel? counsel!\n",
            "\n",
            "KING RICHARD II:\n",
            "My queen and my heir, for half a mile and a half\n",
            "She will glide this way, to be or no.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "So stands the orchard here, for half a mile and a!\n",
            "\n",
            "KING RICHARD II:\n",
            "So stands the orchard here, to fence it, to!\n",
            "Fashion it in her, like the hedgehog's net\n",
            "====================\n",
            "LORD STANLEY:\n",
            "What if I told you, in the hope of succor,\n",
            "That I had lain a little while in your arms?\n",
            "\n",
            "DUKE OF YORK:\n",
            "No doubt, my lord.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "'Tis a pity I should be coil'd to\n",
            "Be brief and unanswerable. Yet give me this.\n",
            "\n",
            "EXTON:\n",
            "'Tis a truth that vexes me deeply\n",
            "To try whether thou, Lord Hastings, art moved\n",
            "To enter publicly with gentle discourse\n",
            "And thanks from his acknowledged friends.\n",
            "\n",
            "HASTINGS:\n",
            "My gracious lord,\n",
            "Suppose me this: did I so love to see the Tower?\n",
            "\n",
            "KING RICHARD II:\n",
            "I did so; but the duelling Tower, moved\n",
            "By jealousies to oppress me,\n",
            "Wretches to usurp him held most dear,\n",
            "The truth is, I loved the Tower as I loved\n",
            "The princes that envied their prosperity.\n",
            "\n",
            "HASTINGS:\n",
            "I loved innocently,\n",
            "When my princes did usurp their gains; when\n",
            "When my grandsire and my liege, prince and prince,\n",
            "B\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "How long shall it take? only\n",
            "To behold your father's bending in the duke's.\n",
            "How long shall it be? do you understand me?\n",
            "\n",
            "ROMEO:\n",
            "Your grace, I understand you.\n",
            "\n",
            "ROMEO:\n",
            "It must be so; then I'll excuse myself.\n",
            "\n",
            "ROMEO:\n",
            "It shall be so.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Your nose is pleasant on myself.\n",
            "\n",
            "ROMEO:\n",
            "No need.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "My heart is troubled by strange thoughts.\n",
            "\n",
            "ROMEO:\n",
            "No need.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "My heart is troubled by strange thoughts.\n",
            "\n",
            "ROMEO:\n",
            "Prithee, be quiet; thou need'st it.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "My mind is unsettled; no need.\n",
            "\n",
            "ROMEO:\n",
            "Prithee, be quiet; thou need'st it.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "My mind is unsettled; no need.\n",
            "\n",
            "ROMEO:\n",
            "Prithee, be quiet; thou need'st it.\n",
            "\n",
            "FRIAR LA\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "And, if the right Edward were slain,\n",
            "My father's blood should wash the world from me.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "O, let him fly from me, that he may live!\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Arise, one last, and let him be slain ere he return.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "I thank God I am not young nor old to waste.\n",
            "I am young and wooer than this young wooer was.\n",
            "\n",
            "YORK:\n",
            "Younger than young, and wooer than a man is.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "What, wilt thou not kill her?\n",
            "\n",
            "RYBHUS:\n",
            "If thou darest, thou hast to do good deeds,\n",
            "If thou darest, thou darest not kill her, thou darest.\n",
            "\n",
            "PRINCE EDWARD:\n",
            "Where dost thou go? command Warwick to take her?\n",
            "\n",
            "WARWICK:\n",
            "Where leadess Warwick be that Warwick is woo'd.\n",
            "\n",
            "YORK:\n",
            "Where leadess Warwick be woo'd that noble York is.\n",
            "\n",
            "PRINCE\n",
            "====================\n",
            "LORD WILLOUGHBY:\n",
            "Let him please to come and sup with him?\n",
            "\n",
            "WARWICK:\n",
            "I promised he should come and sup with him.\n",
            "\n",
            "YORK:\n",
            "'Twas a vow of charity to vex him,\n",
            "And then he should vex us to come and sup.\n",
            "\n",
            "WARWICK:\n",
            "'Twas but a vow to come and sup with him.\n",
            "\n",
            "YORK:\n",
            "'Twas but a vow to come and sup with him.\n",
            "\n",
            "WARWICK:\n",
            "Come hither, slave boy.\n",
            "Me I come, you wretched hag, you wretched thing.\n",
            "\n",
            "DORCAS:\n",
            "'Tis very well. Come, go with me.\n",
            "\n",
            "WARWICK:\n",
            "I will be his slave, and make his bondage known.\n",
            "\n",
            "EXTON:\n",
            "So, you have resisted his bondage, you have run your errand too far.\n",
            "\n",
            "WESTMORELAND:\n",
            "O, but O, the slave that was past the year\n",
            "Doth not my errand a better errand?\n",
            "\n",
            "EXTON:\n",
            "No, for so my wits charge me thus too late.\n",
            "\n",
            "WARWICK:\n",
            "But\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab_type": "code",
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab_type": "code",
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab_type": "code",
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}